{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12a1523-ba68-484f-83fb-9583ac7f8fd5",
   "metadata": {},
   "source": [
    "# ì‹¤í–‰í™˜ê²½ : ìœˆë„ìš°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8cf27-c751-4233-a86b-2d6a10548143",
   "metadata": {},
   "source": [
    "# <span style=\"font-weight:bold\">ì¤‘ê³ ì°¨ ê°€ê²© ì˜ˆì¸¡ì„ ìœ„í•´ ëŒ€í‘œì ì¸ ì¤‘ê³ ì°¨ ì‚¬ì´íŠ¸ Encarì—ì„œ ì •ë³´ íšë“</span>\n",
    "### <span style=\"font-weight:bold\">ê°€ì¥ ëŒ€ì¤‘ì ì´ê³  ë°ì´í„° ê°¯ìˆ˜ê°€ ë§ì€ ë¸Œëœë“œ í˜„ëŒ€ë¥¼ ì„ íƒ, ê·¸ ì¤‘ ì¸ê¸°ê°€ ë§ì€ ìƒìœ„ ì°¨ì¢… ì„ ë³„</span>\n",
    "> <span style=\"color:blue ; font-weight:bold\"> ì œë„¤ì‹œìŠ¤ëŠ” í˜„ëŒ€ì—ì„œ ë¸Œëœë“œ ë¶„ë¦¬ë˜ì—ˆìœ¼ë‚˜ ëŒ€ì¤‘ì ì´ë¼ í•  ë§Œí¼ ì¸ê¸° ì°¨ì¢…ë“¤ì´ ë§ì•„ ì—´ì™¸ë¡œ ì„ íƒ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f57f3-25c5-4e18-b945-43e0dba584f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ì•„ë°˜ë–¼ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f8484-bc33-4e68-afe8-3837e219432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì•„ë°˜ë–¼ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ì•„ë°˜ë–¼ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ì•„ë°˜ë–¼.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ì•„ë°˜ë–¼_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ì•„ë°˜ë–¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì•„ë°˜ë–¼_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ì•„ë°˜ë–¼_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ì•„ë°˜ë–¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f395a7-1d3e-43f1-97b3-2f1425284b36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ì˜ë‚˜íƒ€ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6110e4e-2191-4e26-af5c-1285330d3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì˜ë‚˜íƒ€ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ì˜ë‚˜íƒ€ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ì˜ë‚˜íƒ€.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ì˜ë‚˜íƒ€_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ì˜ë‚˜íƒ€ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì˜ë‚˜íƒ€_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ì˜ë‚˜íƒ€_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ì˜ë‚˜íƒ€_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67f2ed-3a4a-4b20-9e94-e9013b9b5d9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar íˆ¬ì‹¼ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c939f-8b57-45c7-8983-e6440a296c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - íˆ¬ì‹¼ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### íˆ¬ì‹¼ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.íˆ¬ì‹¼.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"íˆ¬ì‹¼_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ íˆ¬ì‹¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"íˆ¬ì‹¼_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('íˆ¬ì‹¼_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'íˆ¬ì‹¼_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db9e35-7c5e-4402-8458-0708dded67e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar íŒ°ë¦¬ì„¸ì´ë“œ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd39b01-c26d-4626-9a34-d601039fef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - íŒ°ë¦¬ì„¸ì´ë“œ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### íŒ°ë¦¬ì„¸ì´ë“œ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.íŒ°ë¦¬ì„¸ì´ë“œ.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ íŒ°ë¦¬ì„¸ì´ë“œ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'íŒ°ë¦¬ì„¸ì´ë“œ_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe0629-cb3e-4ff3-a9b1-3000620f5eaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ìŠ¤íƒ€ë¦¬ì•„ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba24a6-3519-47a8-afbc-37a680a29805",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ìŠ¤íƒ€ë¦¬ì•„ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ìŠ¤íƒ€ë¦¬ì•„ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ìŠ¤íƒ€ë¦¬ì•„.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ìŠ¤íƒ€ë¦¬ì•„ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ìŠ¤íƒ€ë¦¬ì•„_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ìŠ¤íƒ€ë¦¬ì•„_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9393678-c3bf-4b0f-8629-a5f9cc9a243a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ì‹¼íƒ€í˜ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed89012-9a7e-4128-9b91-9b2624d54ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì‹¼íƒ€í˜ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ì‹¼íƒ€í˜ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ì‹¼íƒ€í˜.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ì‹¼íƒ€í˜_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ì‹¼íƒ€í˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì‹¼íƒ€í˜_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ì‹¼íƒ€í˜_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ì‹¼íƒ€í˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74feb240-bba2-4ba6-8026-7306111c9f32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ì½”ë‚˜ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7b8ad-b9a2-4537-b897-e5d448e69aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì½”ë‚˜ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ì½”ë‚˜ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ì½”ë‚˜.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ì½”ë‚˜_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ì½”ë‚˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì½”ë‚˜_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ì½”ë‚˜_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ì½”ë‚˜_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2f6ac-542f-48ee-b7d3-a1e0d9f2e60e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ìŠ¤íƒ€ë ‰ìŠ¤ ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48a74a-401f-4b4e-a69b-9741a27a7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ìŠ¤íƒ€ë ‰ìŠ¤ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ìŠ¤íƒ€ë ‰ìŠ¤ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ìŠ¤íƒ€ë ‰ìŠ¤.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ìŠ¤íƒ€ë ‰ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ìŠ¤íƒ€ë ‰ìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f5d2e-9032-421e-bd99-019d62df6de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ê·¸ëœì € ìë£Œ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce9996-d2c1-4ede-95d6-dec9ca161b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ê·¸ëœì € ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ê·¸ëœì € ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.(C.Manufacturer.í˜„ëŒ€._.ModelGroup.ê·¸ëœì €.)))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ê·¸ëœì €_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ê·¸ëœì € ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ê·¸ëœì €_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ê·¸ëœì €_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ê·¸ëœì €_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e16646-5f9f-4181-82bf-f05cf86b79c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encar ì œë„¤ì‹œìŠ¤ ìë£Œ ìˆ˜ì§‘\n",
    "##### - ì œë„¤ì‹œìŠ¤ëŠ” ë¸Œëœë“œê°€ í˜„ëŒ€ê°€ ì•„ë‹Œ ì œë„¤ì‹œìŠ¤ë¡œ ë˜ì–´ ìˆëŠ” ê´€ê³„ë¡œ API ì£¼ì†Œê°€ ì•½ê°„ ë‹¤ë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e853efb-5421-44f8-8386-884db1c81964",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ENCAR ì‚¬ì´íŠ¸ì—ì„œ ì¤‘ê³ ì°¨ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì œë„¤ì‹œìŠ¤ìŠ¤ ######\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "#### ì œë„¤ì‹œìŠ¤ ê¸°ë³¸ ë°ì´í„° ì €ì¥ ####\n",
    "# Base URL ë° í—¤ë” ì„¤ì •\n",
    "base_url = \"https://api.encar.com/search/car/list/premium\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_data = []\n",
    "offset = 0\n",
    "limit = 20\n",
    "\n",
    "while True:\n",
    "    # API ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"count\": \"true\",\n",
    "        \"q\": \"(And.Hidden.N._.(C.CarType.Y._.Manufacturer.ì œë„¤ì‹œìŠ¤.))\",\n",
    "        \"sr\": f\"|ModifiedDate|{offset}|{limit}\"\n",
    "    }\n",
    "\n",
    "    print(f\"ğŸš€ Fetching data from offset {offset}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "    # SearchResultsì—ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    results = data.get(\"SearchResults\", [])\n",
    "    \n",
    "    if not results:  # ë¹ˆ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬)\n",
    "        print(\"âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ ë˜ëŠ” ë°ì´í„° ì—†ìŒ.\")\n",
    "        break\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_data.extend(results)\n",
    "    print(f\"âœ… Offset {offset}: {len(results)}ê±´ ì¶”ê°€ ì™„ë£Œ (ëˆ„ì : {len(all_data)}ê±´)\")\n",
    "\n",
    "    # ë‹¤ìŒ offsetìœ¼ë¡œ ì´ë™\n",
    "    offset += limit\n",
    "\n",
    "    # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)\n",
    "    time.sleep(1)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    with open(\"ì œë„¤ì‹œìŠ¤_ê¸°ë³¸.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "        json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì´ {len(all_data)}ê±´ì˜ ì œë„¤ì‹œìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ì €ì¥ëœ json íŒŒì¼ì—ì„œ ë°ì´í„° ëŒì–´ì™€ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì œë„¤ì‹œìŠ¤_ê¸°ë³¸.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "car_data = []\n",
    "for car in data:\n",
    "car_data.append({\n",
    "\"Id\": car.get(\"Id\", \"N/A\"),\n",
    "\"ì œì¡°ì‚¬\": car.get(\"Manufacturer\", \"N/A\"),\n",
    "\"ëª¨ë¸ëª…\": car.get(\"Model\", \"N/A\"),\n",
    "\"ë°°ì§€\": car.get(\"Badge\", \"N/A\"), # íŠ¸ë¦¼ ì •ë³´\n",
    "\"ì„¸ë¶€ ë°°ì§€\": car.get(\"BadgeDetail\", \"N/A\"), # ì„¸ë¶€ íŠ¸ë¦¼\n",
    "\"ì—°ì‹\": car.get(\"Year\", \"N/A\"),\n",
    "\"ëª¨ë¸ì—°ë„\": car.get(\"FormYear\", \"N/A\"),\n",
    "\"ê°€ê²©\": car.get(\"Price\", \"N/A\"),\n",
    "\"ì£¼í–‰ê±°ë¦¬\": car.get(\"Mileage\", \"N/A\"),\n",
    "\"ì—°ë£Œ\": car.get(\"FuelType\", \"N/A\"),\n",
    "\"ë³€ì†ê¸°\": car.get(\"Transmission\", \"N/A\"),\n",
    "\"ë“±ë¡ ìƒíƒœ\": car.get(\"ServiceCopyCar\", \"N/A\"), # ì¤‘ë³µ ì°¨ëŸ‰ ì—¬ë¶€\n",
    "\"íŒë§¤ ìœ í˜•\": car.get(\"SellType\", \"N/A\"),\n",
    "\"ë§ˆì§€ë§‰ ìˆ˜ì •ì¼\": car.get(\"ModifiedDate\", \"N/A\"),\n",
    "\"íŒë§¤ì§€ì—­\": car.get(\"OfficeCityState\", \"N/A\"),\n",
    "\"íŒë§¤ì²˜\": car.get(\"OfficeName\", \"N/A\"),\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "\n",
    "### ë“±ë¡ìƒíƒœ DUPLICATION ë‚ ë¦¬ê¸° ###\n",
    "df_unique = df.loc[df['ë“±ë¡ ìƒíƒœ']!='DUPLICATION']\n",
    "\n",
    "\n",
    "### ê¸°ë³¸ ì •ë³´ ì•ˆì—ì„œ Id ì¤‘ë³µ ì œê±° ###\n",
    "df_unique = df_unique.drop_duplicates(subset='Id')\n",
    "df_unique.to_csv('ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### ê¸°ì¡´ ë°ì´í„° ì¤‘ Idë¡œ ë‹¤ë¥¸ APIë¥¼ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸ ê°€ì ¸ì˜¨ í›„ ìƒˆë¡œìš´ ì—´ë¡œ ì¶”ê°€ ####\n",
    "\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique = pd.read_csv('ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°.csv')\n",
    "\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/vehicle/{Id}?include=CONTENTS\"\n",
    "\n",
    "# vehicleNo ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "vehicle_numbers = []\n",
    "\n",
    "# ê° Idì— ëŒ€í•´ API í˜¸ì¶œ ë° JSON ì €ì¥í•˜ê¸°\n",
    "for idx, car_id in enumerate(df_unique['Id'], start=1):\n",
    "url = base_url.format(Id=car_id)\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# vehicleNo ì¶”ì¶œ\n",
    "vehicle_no = data.get('vehicleNo', None)\n",
    "vehicle_numbers.append(vehicle_no)\n",
    "print(f\"Processed {idx}/{len(df_unique)}: ID={car_id}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}: {e}\")\n",
    "vehicle_numbers.append(None)\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ì›ë³¸ DataFrameì— vehicleNo ì—´ ì¶”ê°€í•˜ê¸°\n",
    "df_unique['ì°¨ëŸ‰ë²ˆí˜¸'] = vehicle_numbers\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_unique.to_csv('ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Idì™€ ì°¨ëŸ‰ë²ˆí˜¸ ì´ìš©í•´ ë³´í—˜ì´ë ¥ ë°ì´í„° ê°€ì ¸ì™€ json íŒŒì¼ë¡œ ì €ì¥ ####\n",
    "\n",
    "\n",
    "# ì°¨ëŸ‰ ë²ˆí˜¸ ì¶”ê°€í•œ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_unique_no = pd.read_csv('ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸.csv')\n",
    "df_unique_no = df_unique_no.rename(columns={'vehicleNo':'ì°¨ëŸ‰ë²ˆí˜¸'})\n",
    "# API ê¸°ë³¸ URL ì„¤ì •\n",
    "base_url = \"https://api.encar.com/v1/readside/record/vehicle/{Id}/open?vehicleNo={CarNo}\"\n",
    "\n",
    "# JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "all_data = []\n",
    "\n",
    "# ê° Idì™€ vehicleNoì— ëŒ€í•´ API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘\n",
    "for idx, row in df_unique_no.iterrows():\n",
    "car_id = row['Id']\n",
    "vehicle_no = row['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "url = base_url.format(Id=car_id, CarNo=vehicle_no)\n",
    "\n",
    "try:\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "all_data.append(data)\n",
    "\n",
    "# ì§„í–‰ ìƒíƒœ ì¶œë ¥\n",
    "print(f\"Processed {idx + 1}/{len(df_unique_no)}: ID={car_id}, Vehicle No={vehicle_no}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "print(f\"Error fetching data for ID {car_id}, Vehicle No {vehicle_no}: {e}\")\n",
    "\n",
    "# ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì¶”ê°€\n",
    "time.sleep(0.5)\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(\"ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"w\", encoding='utf-8-sig') as json_file:\n",
    "json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All data has been saved to 'ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### jsonë°ì´í„°ì—ì„œ ì›í•˜ëŠ” ë³´í—˜ì´ë ¥ ì •ë³´ ì„ íƒí•´ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° ####\n",
    "\n",
    "with open(\"ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "data = json.load(file)\n",
    "\n",
    "# í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ\n",
    "insurance_data = []\n",
    "for insurance in data:\n",
    "insurance_data.append({\n",
    "\"ì°¨ëŸ‰ë²ˆí˜¸\": insurance.get(\"carNo\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´\": insurance.get(\"myAccidentCnt\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´\": insurance.get(\"otherAccidentCnt\", \"N/A\"),\n",
    "\"ì†Œìœ ìë³€ê²½ì´ë ¥\": insurance.get(\"ownerChangeCnt\", \"N/A\"),\n",
    "\"ë‚´ì°¨í”¼í•´ê¸ˆì•¡\": insurance.get(\"myAccidentCost\", \"N/A\"),\n",
    "\"íƒ€ì°¨ê°€í•´ê¸ˆì•¡\": insurance.get(\"otherAccidentCost\", \"N/A\"),\n",
    "\"ë²ˆí˜¸íŒë³€ê²½ì´ë ¥\": insurance.get(\"carNoChangeCnt\", \"N/A\"),\n",
    "\"ì „ì²´ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodTotalLossCnt\", \"N/A\"),\n",
    "\"ì¼ë¶€ì¹¨ìˆ˜íšŸìˆ˜\": insurance.get(\"floodPartLossCnt\", \"N/A\"),\n",
    "})\n",
    "ins = pd.DataFrame(insurance_data)\n",
    "\n",
    "#ì¤‘ë³µ ì œê±°\n",
    "print(f\"ê¸°ì¡´ í–‰ ìˆ˜: {len(ins)}\")\n",
    "ins = ins.drop_duplicates()\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(ins)}\")\n",
    "\n",
    "\n",
    "#ê¸°ì¡´ ê¸°ë³¸ ì •ë³´ì˜ ê¸ˆì•¡ ë‹¨ìœ„ì™€ ë§ì¶”ê¸° ìœ„í•´ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡'] = ins['ë‚´ì°¨í”¼í•´ê¸ˆì•¡']/10000\n",
    "ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡'] = ins['íƒ€ì°¨ê°€í•´ê¸ˆì•¡']/10000\n",
    "\n",
    "\n",
    "# csv íŒŒì¼ë¡œ ë°±ì—…\n",
    "ins.to_csv('ì œë„¤ì‹œìŠ¤_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì°¨ëŸ‰ë²ˆí˜¸ ì¶”ê°€í•œ ê¸°ë³¸ ì •ë³´ì— ë³´í—˜ ì´ë ¥ ì¶”ê°€\n",
    "df_unique_no_ins = pd.merge(df_unique_no, ins, on='ì°¨ëŸ‰ë²ˆí˜¸', how='inner')\n",
    "\n",
    "\n",
    "df_unique_no_ins.to_csv('ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"All data has been saved to 'ì œë„¤ì‹œìŠ¤_ê¸°ë³¸_ì¤‘ë³µì œê±°_ì°¨ëŸ‰ë²ˆí˜¸_ë³´í—˜ì´ë ¥.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
